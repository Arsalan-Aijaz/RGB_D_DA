{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f2d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from NeuralNetwork import ResBase, MainHead, RotationHead\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import permutations\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81fe8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = list(permutations(range(4)))\n",
    "mean = [0.485, 0.456, 0.40]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image_c, image_d):\n",
    "\n",
    "        h1, w1 = image_c.height, image_c.width\n",
    "        h2, w2 = image_d.height, image_d.width\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h1 > w1:\n",
    "                new_h1, new_w1 = self.output_size * h1 / w1, self.output_size\n",
    "            else:\n",
    "                new_h1, new_w1 = self.output_size, self.output_size * w1 / h1\n",
    "            if h2 > w2:\n",
    "                new_h2, new_w2 = self.output_size * h2 / w2, self.output_size\n",
    "            else:\n",
    "                new_h2, new_w2 = self.output_size, self.output_size * w2 / h2\n",
    "        else:\n",
    "            new_h1, new_w1 = self.output_size\n",
    "            new_h2, new_w2 = self.output_size\n",
    "\n",
    "        new_h1, new_w1 = int(new_h1), int(new_w1)\n",
    "        new_h2, new_w2 = int(new_h2), int(new_w2)\n",
    "\n",
    "        img1 = image_c.resize((new_h1, new_w1))\n",
    "        img2 = image_d.resize((new_h2, new_w2))\n",
    "\n",
    "        return img1, img2\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image_c, image_d):\n",
    "        h1, w1 = image_c.height, image_c.width\n",
    "        h2, w2 = image_d.height, image_d.width\n",
    "\n",
    "        new_h1, new_w1 = self.output_size\n",
    "        new_h2, new_w2 = self.output_size\n",
    "\n",
    "        top1 = np.random.randint(0, h1 - new_h1)\n",
    "        left1 = np.random.randint(0, w1 - new_w1)\n",
    "        top2 = np.random.randint(0, h2 - new_h2)\n",
    "        left2 = np.random.randint(0, w2 - new_w2)\n",
    "\n",
    "        img1 = image_c.crop((left1, h1 - new_h1, left1 + new_w1, h1))\n",
    "        img2 = image_d.crop((left2, h2 - new_h2, left2 + new_w2, h2))\n",
    "\n",
    "        return img1, img2\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image_c, image_d):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        img1 = transforms.ToTensor()(image_c)\n",
    "        img2 = transforms.ToTensor()(image_d)\n",
    "        return img1, img2\n",
    "\n",
    "\n",
    "scale = Rescale(256)\n",
    "crop = RandomCrop(224)\n",
    "tensor = ToTensor()\n",
    "\n",
    "\n",
    "def make_jigsaw(img1, z):\n",
    "    img1 = img1.to('cpu')\n",
    "    img2 = transforms.ToPILImage()(img1[0:3])\n",
    "    img2 = img2.resize((224, 224))\n",
    "    img1 = transforms.ToPILImage()(img1[3:6])\n",
    "    img1 = img1.resize((224, 224))\n",
    "    blockmap1 = [(0, 0, 112, 112), (0, 112, 112, 224), (112, 0, 224, 112), (112, 112, 224, 224)]\n",
    "    blockmap2 = [(0, 0, 112, 112), (0, 112, 112, 224), (112, 0, 224, 112), (112, 112, 224, 224)]\n",
    "    shuffle = list(blockmap1)\n",
    "    shuffle = list(map(shuffle.__getitem__, perms[z]))\n",
    "    result1 = Image.new(mode=\"RGB\", size=(224, 224))\n",
    "    result2 = Image.new(mode=\"RGB\", size=(224, 224))\n",
    "    for box1, box2, sbox in zip(blockmap1, blockmap2, shuffle):\n",
    "        c = img1.crop(sbox)\n",
    "        d = img2.crop(sbox)\n",
    "        result1.paste(c, box1)\n",
    "        result2.paste(d, box2)\n",
    "    result = torch.cat((transforms.functional.pil_to_tensor(result1), transforms.functional.pil_to_tensor(result2)), 0)\n",
    "    return result\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, paths_c, paths_d, img_dir, DoRot=False, labels=\"\",\n",
    "                 transform=None, ROD=False, Jigsaw=False):\n",
    "        self.paths_c = paths_c\n",
    "        self.paths_d = paths_d\n",
    "        self.img_labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.DoRot = DoRot\n",
    "        self.Jigsaw = Jigsaw\n",
    "        self.ROD = ROD\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths_c)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if self.ROD:\n",
    "            rgb_path = os.path.join(self.img_dir, \"rgb-washington/\", self.paths_c.values[idx])\n",
    "            depth_path = os.path.join(self.img_dir, \"surfnorm-washington/\", self.paths_d.values[idx])\n",
    "            image_c = Image.open(rgb_path)\n",
    "            image_d = Image.open(depth_path)\n",
    "        else:\n",
    "            rgb_path = os.path.join(self.img_dir, self.paths_c[idx])\n",
    "            depth_path = os.path.join(self.img_dir, self.paths_d[idx])\n",
    "            image_c = Image.open(rgb_path)\n",
    "            image_d = Image.open(depth_path)\n",
    "        if self.DoRot:\n",
    "            z = random.choice((0, 1, 2, 3))\n",
    "        elif self.Jigsaw:\n",
    "            z = len(perms) - 1\n",
    "            z = random.randint(0, z)\n",
    "        else:\n",
    "            z = 0\n",
    "        if self.img_labels != \"\" and self.img_labels != []:\n",
    "            label = self.img_labels[idx]\n",
    "        else:\n",
    "            label = 0\n",
    "        if self.transform:\n",
    "            image_c, image_d = scale(image_c, image_d)\n",
    "            image_c, image_d = crop(image_c, image_d)\n",
    "            image_c, image_d = tensor(image_c, image_d)\n",
    "            transforms.Normalize(mean, std, inplace=True)(image_c)\n",
    "            transforms.Normalize(mean, std, inplace=True)(image_d)\n",
    "        x = torch.cat((image_c, image_d), 0)\n",
    "        return x, label, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e81e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(type, batch_size):\n",
    "    # prepare data\n",
    "    df_synROD_train = pd.read_csv('newdata/ROD-synROD/synROD/synARID_50k-split_sync_train1.txt',\n",
    "                                  delimiter=' ', header=0, names=['File', 'Label'])\n",
    "    df_synROD_test = pd.read_csv('newdata/ROD-synROD/synROD/synARID_50k-split_sync_test1.txt',\n",
    "                                 delimiter=' ', header=0, names=['File', 'Label'])\n",
    "    df_ROD_train = pd.read_csv('newdata/ROD-synROD/ROD/wrgbd_40k-split_sync.txt',\n",
    "                               delimiter=' ', header=0, names=['File', 'Label'])\n",
    "\n",
    "    train_synROD = dict(RGBfile=[], Dfile=[], Label=[])\n",
    "    test_synROD = dict(RGBfile=[], Dfile=[], Label=[])\n",
    "    train_ROD = dict(RGBfile=[], Dfile=[], Label=[])\n",
    "    test_ROD = dict(RGBfile=[], Dfile=[])\n",
    "\n",
    "    train_synROD[\"RGBfile\"] = (df_synROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"rgb\"))).map(str)\n",
    "    train_synROD[\"Dfile\"] = (df_synROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"depth\"))).map(str)\n",
    "    train_synROD[\"Label\"] = df_synROD_train[\"Label\"].values.tolist()\n",
    "\n",
    "    test_synROD[\"RGBfile\"] = (df_synROD_test[\"File\"].apply(lambda x: x.replace(\"***\", \"rgb\"))).map(str)\n",
    "    test_synROD[\"Dfile\"] = (df_synROD_test[\"File\"].apply(lambda x: x.replace(\"***\", \"depth\"))).map(str)\n",
    "    test_synROD[\"Label\"] = df_synROD_test[\"Label\"].values.tolist()\n",
    "\n",
    "    train_ROD[\"RGBfile\"] = (df_ROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"crop\"))).map(str)\n",
    "    train_ROD[\"Dfile\"] = (df_ROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"depthcrop\"))).map(str)\n",
    "\n",
    "    test_ROD[\"RGBfile\"] = (df_ROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"crop\"))).map(str)\n",
    "    test_ROD[\"Dfile\"] = (df_ROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"depthcrop\"))).map(str)\n",
    "    test_ROD[\"Label\"] = df_ROD_train[\"Label\"].values.tolist()\n",
    "\n",
    "    if type == 'Jigsaw':\n",
    "        training_data_synROD = CustomImageDataset(train_synROD[\"RGBfile\"], train_synROD[\"Dfile\"],\n",
    "                                                  img_dir=\"newdata/ROD-synROD/synROD/\",\n",
    "                                                  labels=train_synROD[\"Label\"],\n",
    "                                                  transform=True, ROD=False, Jigsaw=True)\n",
    "\n",
    "        RGB_train, RGB_test, label_train, label_test = train_test_split(test_ROD[\"RGBfile\"], test_ROD[\"Label\"],\n",
    "                                                                        test_size=0.3, random_state=42)\n",
    "        D_train, D_test, _, _ = train_test_split(test_ROD[\"Dfile\"], test_ROD[\"Label\"], test_size=0.3, random_state=42)\n",
    "        test_data = CustomImageDataset(RGB_test, D_test, img_dir=\"newdata/ROD-synROD/ROD/\",\n",
    "                                       labels=label_test, transform=True, ROD=True, Jigsaw=True)\n",
    "        training_data_ROD = CustomImageDataset(RGB_train, D_train, img_dir=\"newdata/ROD-synROD/ROD/\",\n",
    "                                               transform=True, ROD=True, Jigsaw=True)\n",
    "        train_dataloader_synROD = DataLoader(training_data_synROD, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                             num_workers=2, drop_last=True)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2, drop_last=True)\n",
    "        dataloaders = dict(train=train_dataloader_synROD, val=test_dataloader)\n",
    "    elif type == 'DA':\n",
    "\n",
    "        training_data_synROD = CustomImageDataset(train_synROD[\"RGBfile\"], train_synROD[\"Dfile\"], DoRot=True,\n",
    "                                                  img_dir=\"newdata/ROD-synROD/synROD/\",\n",
    "                                                  labels=train_synROD[\"Label\"],\n",
    "                                                  transform=True, ROD=False)\n",
    "\n",
    "        RGB_train, RGB_test, label_train, label_test = train_test_split(test_ROD[\"RGBfile\"], test_ROD[\"Label\"],\n",
    "                                                                        test_size=0.3, random_state=42)\n",
    "        D_train, D_test, _, _ = train_test_split(test_ROD[\"Dfile\"], test_ROD[\"Label\"],\n",
    "                                                 test_size=0.3, random_state=42)\n",
    "        test_data = CustomImageDataset(RGB_test, D_test, DoRot=False,\n",
    "                                       img_dir=\"newdata/ROD-synROD/ROD/\", labels=label_test,\n",
    "                                       transform=True, ROD=True)\n",
    "        training_data_ROD = CustomImageDataset(RGB_train, D_train, DoRot=True,\n",
    "                                               img_dir=\"newdata/ROD-synROD/ROD/\", transform=True, ROD=True)\n",
    "        train_dataloader_synROD = DataLoader(training_data_synROD, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                             num_workers=2, drop_last=True)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2,\n",
    "                                     drop_last=True)\n",
    "        dataloaders = dict(train=train_dataloader_synROD, val=test_dataloader)\n",
    "    else:\n",
    "        training_data_e2e = CustomImageDataset(train_synROD[\"RGBfile\"], train_synROD[\"Dfile\"], DoRot=False,\n",
    "                                               img_dir=\"newdata/ROD-synROD/synROD/\", labels=train_synROD[\"Label\"],\n",
    "                                               transform=True, ROD=False)\n",
    "        test_data_e2e = CustomImageDataset(test_ROD[\"RGBfile\"], train_ROD[\"Dfile\"], DoRot=False,\n",
    "                                           img_dir=\"newdata/ROD-synROD/ROD/\", labels=test_ROD[\"Label\"],\n",
    "                                           transform=True, ROD=True)\n",
    "        training_data_ROD = CustomImageDataset(train_ROD[\"RGBfile\"], train_ROD[\"Dfile\"], DoRot=True,\n",
    "                                               img_dir=\"newdata/ROD-synROD/ROD/\", transform=True, ROD=True)\n",
    "        train_dataloader_e2e = DataLoader(training_data_e2e, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                          num_workers=4)\n",
    "        test_dataloader_e2e = DataLoader(test_data_e2e, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                         num_workers=4)\n",
    "        dataloaders = dict(train=train_dataloader_e2e, val=test_dataloader_e2e)\n",
    "\n",
    "    train_dataloader_ROD = DataLoader(training_data_ROD, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                      num_workers=0, drop_last=True)\n",
    "\n",
    "    return dataloaders, train_dataloader_ROD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcfd68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_DA(num_epochs=20, batch_size=64, mode=\"Rotation\"):\n",
    "    FE_rgb = ResBase()\n",
    "    FE_depth = ResBase()\n",
    "    FC_M = MainHead(input_dim=512 * 2, class_num=47, dropout_p=0.5, extract=False)\n",
    "    if mode == \"Rotation\":\n",
    "        FC_P = RotationHead(input_dim=1024, class_num=4)\n",
    "        dataloaders, target_dataloader = prep_data('DA', batch_size)\n",
    "    else:\n",
    "        FC_P = RotationHead(input_dim=1024, class_num=24)\n",
    "        dataloaders, target_dataloader = prep_data('Jigsaw', batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    FE_rgb, FE_depth, FC_M, FC_P = FE_rgb.to(device), FE_depth.to(device), FC_M.to(device), FC_P.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    pretext_weight = 0.4\n",
    "    optimizers = [optim.SGD(FE_rgb.parameters(), lr=3e-3, weight_decay=0.05, momentum=0.9),\n",
    "                  optim.SGD(FE_depth.parameters(), lr=3e-3, weight_decay=0.05, momentum=0.9),\n",
    "                  optim.SGD(FC_M.parameters(), lr=3e-3, weight_decay=0.05, momentum=0.9),\n",
    "                  optim.SGD(FC_P.parameters(), lr=3e-3, weight_decay=0.05, momentum=0.9)]\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(FE_rgb.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Store losses and accuracies across epochs\n",
    "    losses, accuracies, lr = dict(train=[], val=[]), dict(train=[], val=[]), 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                FE_rgb.train()\n",
    "                FE_depth.train()\n",
    "                FC_M.train()\n",
    "                FC_P.train()\n",
    "            else:\n",
    "                FE_rgb.eval()\n",
    "                FE_depth.eval()\n",
    "                FC_M.eval()\n",
    "                FC_P.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            nsamples = 0\n",
    "            for x_source, y_source, z_source in dataloaders[phase]:  # Loading mini-batch from S\n",
    "                # Load mini-batch from S\n",
    "                x_source, y_source = x_source.to(device), y_source.to(device)\n",
    "                nsamples += x_source.shape[0]\n",
    "                for optimizer in optimizers:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Compute main loss Lm\n",
    "                    feats_rgb, _ = FE_rgb(x_source[:, [0, 1, 2]])\n",
    "                    feats_depth, _ = FE_depth(x_source[:, [3, 4, 5]])\n",
    "                    feats = torch.cat((feats_rgb, feats_depth), dim=1)\n",
    "                    pred_logits_cat = FC_M(feats)\n",
    "                    _, preds_cat = torch.max(pred_logits_cat, 1)\n",
    "                    Lm = criterion(pred_logits_cat, y_source)\n",
    "\n",
    "                    # Load mini-batches from S~ and T~\n",
    "                    x_target, _, z_target = next(iter(target_dataloader))\n",
    "\n",
    "                    # print_image(x_target[0])\n",
    "                    # print_image(x_target_tilde[0])\n",
    "                    x_target = x_target.to(device)\n",
    "\n",
    "                    InTilde = torch.zeros(size=(batch_size, 6, 224, 224), device=device)\n",
    "                    InZ = torch.zeros(size=[batch_size], device=device, dtype=torch.uint8)\n",
    "                    for idx in range(0, batch_size, 2):\n",
    "                        if mode == \"Jigsaw\":\n",
    "                            InTilde[idx] = make_jigsaw(x_source[idx], z_source[idx].item())\n",
    "                            InTilde[idx + 1] = make_jigsaw(x_target[idx], z_target[idx].item())\n",
    "                        else:\n",
    "                            rot_c = random.choice((0, 1, 2, 3))\n",
    "                            rot_d = z_source[idx].item() + rot_c\n",
    "                            if rot_d >= 4:\n",
    "                                rot_d -= 4\n",
    "                            InTilde[idx][0:3] = transforms.functional.rotate(x_source[idx][0:3], rot_c * 90)\n",
    "                            InTilde[idx][3:6] = transforms.functional.rotate(x_source[idx][3:6], rot_d * 90)\n",
    "                            rot_c = random.choice((0, 1, 2, 3))\n",
    "                            rot_d = z_target[idx].item() + rot_c\n",
    "                            if rot_d > 4:\n",
    "                                rot_d -= 4\n",
    "                            InTilde[idx + 1] = transforms.functional.rotate(x_target[idx], z_target[idx].item() * 90)\n",
    "                        InZ[idx] = z_source[idx].data\n",
    "                        InZ[idx + 1] = z_target[idx].data\n",
    "                    _, feats_rgb = FE_rgb(InTilde[:, [0, 1, 2]])\n",
    "                    _, feats_depth = FE_depth(InTilde[:, [3, 4, 5]])\n",
    "                    feats = torch.cat((feats_rgb, feats_depth), dim=1)\n",
    "                    pred_logits_rot = FC_P(feats)\n",
    "                    _, preds_rot = torch.max(pred_logits_rot, 1)\n",
    "                    Lp = criterion(pred_logits_rot, InZ)\n",
    "\n",
    "                    # Cross-entropy minimization\n",
    "                    L = Lm + (pretext_weight * Lp)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        L.backward()\n",
    "                        for optimizer in optimizers:\n",
    "                            optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += Lm.item() * (x_target.size(0))\n",
    "                running_corrects += (preds_cat == y_source.data).sum().item()\n",
    "                #print('Phase: {} Progress: {}/{} Lm: {:.4f} Lp: {:.4f} L: {:.4f}'.format(phase, nsamples, dataloaders[\n",
    "                #    phase].sampler.num_samples, Lm.item(), Lp.item(), L.item()))\n",
    "\n",
    "            epoch_loss = running_loss / nsamples\n",
    "            epoch_acc = running_corrects / nsamples\n",
    "\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            lr = optimizers[0].param_groups[0]['lr']\n",
    "            print('Phase: {} LR: {:.4f} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, lr, epoch_loss, epoch_acc))\n",
    "            with open('result_rotation.txt', 'a') as fp:\n",
    "                fp.write('Phase: {}, LR: {:.4f}, Loss: {:.4f}, Acc: {:.4f}\\n'.format(phase, lr, epoch_loss, epoch_acc))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_FC_M_wts = copy.deepcopy(FC_M.state_dict())\n",
    "                best_FC_P_wts = copy.deepcopy(FC_P.state_dict())\n",
    "                best_FE_rgb_wts = copy.deepcopy(FE_rgb.state_dict())\n",
    "                best_FE_depth_wts = copy.deepcopy(FE_depth.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    with open('result_rotation.txt', 'a') as fp:\n",
    "        fp.write(('Training complete in {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60)))\n",
    "        fp.write('Best val Acc: {:4f}\\n'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    FC_M.load_state_dict(best_FC_M_wts)\n",
    "    FC_P.load_state_dict(best_FC_P_wts)\n",
    "    FE_rgb.load_state_dict(best_FE_rgb_wts)\n",
    "    FE_depth.load_state_dict(best_FE_depth_wts)\n",
    "    return FC_M, FC_P, FE_rgb, FE_depth, losses, accuracies, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e56c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.0657 Acc: 0.7729\n",
      "Phase: val LR: 0.0030 Loss: 3.9544 Acc: 0.0195\n",
      "Epoch 2/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 0.8849 Acc: 0.8961\n"
     ]
    }
   ],
   "source": [
    "    FC_M, FC_P, FE_rgb, FE_depth, losses, accuracies, lr = train_model_DA(num_epochs=20, batch_size=64, mode=\"Jigsaw\")\n",
    "    save_filename = 'DA_jigsaw.pth'\n",
    "    save_path = os.path.join('./savedModels', save_filename)\n",
    "    torch.save({'FC_M_state_dict': FC_M.state_dict(),\n",
    "                'FC_P_state_dict': FC_P.state_dict(),\n",
    "                'FE_rgb_state_dict': FE_rgb.state_dict(),\n",
    "                'FE_depth_state_dict': FE_depth.state_dict(),\n",
    "    }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9361101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.0256 Acc: 0.7828\n",
      "Phase: val LR: 0.0030 Loss: 2.5715 Acc: 0.3769\n",
      "Epoch 2/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 0.8739 Acc: 0.8977\n",
      "Phase: val LR: 0.0030 Loss: 3.0359 Acc: 0.2845\n",
      "Epoch 3/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.2626 Acc: 0.8519\n",
      "Phase: val LR: 0.0030 Loss: 3.2657 Acc: 0.1685\n",
      "Epoch 4/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.4620 Acc: 0.8200\n",
      "Phase: val LR: 0.0030 Loss: 3.2307 Acc: 0.1780\n",
      "Epoch 5/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5021 Acc: 0.8156\n",
      "Phase: val LR: 0.0030 Loss: 3.2188 Acc: 0.2126\n",
      "Epoch 6/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5050 Acc: 0.8112\n",
      "Phase: val LR: 0.0030 Loss: 3.1780 Acc: 0.2310\n",
      "Epoch 7/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5006 Acc: 0.8147\n",
      "Phase: val LR: 0.0030 Loss: 3.2391 Acc: 0.2013\n",
      "Epoch 8/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5098 Acc: 0.8103\n",
      "Phase: val LR: 0.0030 Loss: 3.2973 Acc: 0.1794\n",
      "Epoch 9/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.4977 Acc: 0.8118\n",
      "Phase: val LR: 0.0030 Loss: 3.2615 Acc: 0.1680\n",
      "Epoch 10/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.4948 Acc: 0.8120\n",
      "Phase: val LR: 0.0030 Loss: 3.3222 Acc: 0.1738\n",
      "Epoch 11/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.4904 Acc: 0.8129\n",
      "Phase: val LR: 0.0030 Loss: 3.2838 Acc: 0.1772\n",
      "Epoch 12/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.4942 Acc: 0.8103\n",
      "Phase: val LR: 0.0030 Loss: 3.2360 Acc: 0.2052\n",
      "Epoch 13/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5052 Acc: 0.8076\n",
      "Phase: val LR: 0.0030 Loss: 3.2813 Acc: 0.1564\n",
      "Epoch 14/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.4966 Acc: 0.8113\n",
      "Phase: val LR: 0.0030 Loss: 3.5597 Acc: 0.1299\n",
      "Epoch 15/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.4978 Acc: 0.8085\n",
      "Phase: val LR: 0.0030 Loss: 3.3265 Acc: 0.1702\n",
      "Epoch 16/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5021 Acc: 0.8065\n",
      "Phase: val LR: 0.0030 Loss: 3.5405 Acc: 0.1113\n",
      "Epoch 17/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5091 Acc: 0.8057\n",
      "Phase: val LR: 0.0030 Loss: 3.1465 Acc: 0.2368\n",
      "Epoch 18/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5082 Acc: 0.8051\n",
      "Phase: val LR: 0.0030 Loss: 3.3321 Acc: 0.1616\n",
      "Epoch 19/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5104 Acc: 0.8031\n",
      "Phase: val LR: 0.0030 Loss: 3.3518 Acc: 0.1696\n",
      "Epoch 20/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5071 Acc: 0.8049\n",
      "Phase: val LR: 0.0030 Loss: 3.3356 Acc: 0.1674\n",
      "Training complete in 148m 47s\n",
      "Best val Acc: 0.376850\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2049/4059405991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_da\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_DA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Rotation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "model_da, losses, accuracies, lr = train_model_DA(num_epochs=20, batch_size=64, mode=\"Jigsaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfb55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
