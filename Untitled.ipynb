{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e8ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from NeuralNetwork import ResBase, MainHead, RotationHead\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import permutations\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe231156",
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = list(permutations(range(4)))\n",
    "mean = [0.485, 0.456, 0.40]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image_c, image_d):\n",
    "\n",
    "        h1, w1 = image_c.height, image_c.width\n",
    "        h2, w2 = image_d.height, image_d.width\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h1 > w1:\n",
    "                new_h1, new_w1 = self.output_size * h1 / w1, self.output_size\n",
    "            else:\n",
    "                new_h1, new_w1 = self.output_size, self.output_size * w1 / h1\n",
    "            if h2 > w2:\n",
    "                new_h2, new_w2 = self.output_size * h2 / w2, self.output_size\n",
    "            else:\n",
    "                new_h2, new_w2 = self.output_size, self.output_size * w2 / h2\n",
    "        else:\n",
    "            new_h1, new_w1 = self.output_size\n",
    "            new_h2, new_w2 = self.output_size\n",
    "\n",
    "        new_h1, new_w1 = int(new_h1), int(new_w1)\n",
    "        new_h2, new_w2 = int(new_h2), int(new_w2)\n",
    "\n",
    "        img1 = image_c.resize((new_h1, new_w1))\n",
    "        img2 = image_d.resize((new_h2, new_w2))\n",
    "\n",
    "        return img1, img2\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image_c, image_d):\n",
    "        h1, w1 = image_c.height, image_c.width\n",
    "        h2, w2 = image_d.height, image_d.width\n",
    "\n",
    "        new_h1, new_w1 = self.output_size\n",
    "        new_h2, new_w2 = self.output_size\n",
    "\n",
    "        top1 = np.random.randint(0, h1 - new_h1)\n",
    "        left1 = np.random.randint(0, w1 - new_w1)\n",
    "        top2 = np.random.randint(0, h2 - new_h2)\n",
    "        left2 = np.random.randint(0, w2 - new_w2)\n",
    "\n",
    "        img1 = image_c.crop((left1, h1 - new_h1, left1 + new_w1, h1))\n",
    "        img2 = image_d.crop((left2, h2 - new_h2, left2 + new_w2, h2))\n",
    "\n",
    "        return img1, img2\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image_c, image_d):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        img1 = transforms.ToTensor()(image_c)\n",
    "        img2 = transforms.ToTensor()(image_d)\n",
    "        return img1, img2\n",
    "\n",
    "\n",
    "scale = Rescale(256)\n",
    "crop = RandomCrop(224)\n",
    "tensor = ToTensor()\n",
    "\n",
    "\n",
    "def make_jigsaw(img1, z):\n",
    "    img1 = img1.to('cpu')\n",
    "    img2 = transforms.ToPILImage()(img1[0:3])\n",
    "    img2 = img2.resize((224, 224))\n",
    "    img1 = transforms.ToPILImage()(img1[3:6])\n",
    "    img1 = img1.resize((224, 224))\n",
    "    blockmap1 = [(0, 0, 112, 112), (0, 112, 112, 224), (112, 0, 224, 112), (112, 112, 224, 224)]\n",
    "    blockmap2 = [(0, 0, 112, 112), (0, 112, 112, 224), (112, 0, 224, 112), (112, 112, 224, 224)]\n",
    "    shuffle = list(blockmap1)\n",
    "    shuffle = list(map(shuffle.__getitem__, perms[z]))\n",
    "    result1 = Image.new(mode=\"RGB\", size=(224, 224))\n",
    "    result2 = Image.new(mode=\"RGB\", size=(224, 224))\n",
    "    for box1, box2, sbox in zip(blockmap1, blockmap2, shuffle):\n",
    "        c = img1.crop(sbox)\n",
    "        d = img2.crop(sbox)\n",
    "        result1.paste(c, box1)\n",
    "        result2.paste(d, box2)\n",
    "    result = torch.cat((transforms.functional.pil_to_tensor(result1), transforms.functional.pil_to_tensor(result2)), 0)\n",
    "    return result\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, paths_c, paths_d, img_dir, DoRot=False, labels=\"\",\n",
    "                 transform=None, ROD=False, Jigsaw=False):\n",
    "        self.paths_c = paths_c\n",
    "        self.paths_d = paths_d\n",
    "        self.img_labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.DoRot = DoRot\n",
    "        self.Jigsaw = Jigsaw\n",
    "        self.ROD = ROD\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths_c)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if self.ROD:\n",
    "            rgb_path = os.path.join(self.img_dir, \"rgb-washington/\", self.paths_c.values[idx])\n",
    "            depth_path = os.path.join(self.img_dir, \"surfnorm-washington/\", self.paths_d.values[idx])\n",
    "            image_c = Image.open(rgb_path)\n",
    "            image_d = Image.open(depth_path)\n",
    "        else:\n",
    "            rgb_path = os.path.join(self.img_dir, self.paths_c[idx])\n",
    "            depth_path = os.path.join(self.img_dir, self.paths_d[idx])\n",
    "            image_c = Image.open(rgb_path)\n",
    "            image_d = Image.open(depth_path)\n",
    "        if self.DoRot:\n",
    "            z = random.choice((0, 1, 2, 3))\n",
    "        elif self.Jigsaw:\n",
    "            z = len(perms) - 1\n",
    "            z = random.randint(0, z)\n",
    "        else:\n",
    "            z = 0\n",
    "        if self.img_labels != \"\" and self.img_labels != []:\n",
    "            label = self.img_labels[idx]\n",
    "        else:\n",
    "            label = 0\n",
    "        if self.transform:\n",
    "            image_c, image_d = scale(image_c, image_d)\n",
    "            image_c, image_d = crop(image_c, image_d)\n",
    "            image_c, image_d = tensor(image_c, image_d)\n",
    "            transforms.Normalize(mean, std, inplace=True)(image_c)\n",
    "            transforms.Normalize(mean, std, inplace=True)(image_d)\n",
    "        x = torch.cat((image_c, image_d), 0)\n",
    "        return x, label, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cd5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(type, batch_size):\n",
    "    # prepare data\n",
    "    df_synROD_train = pd.read_csv('newdata/ROD-synROD/synROD/synARID_50k-split_sync_train1.txt',\n",
    "                                  delimiter=' ', header=0, names=['File', 'Label'])\n",
    "    df_synROD_test = pd.read_csv('newdata/ROD-synROD/synROD/synARID_50k-split_sync_test1.txt',\n",
    "                                 delimiter=' ', header=0, names=['File', 'Label'])\n",
    "    df_ROD_train = pd.read_csv('newdata/ROD-synROD/ROD/wrgbd_40k-split_sync.txt',\n",
    "                               delimiter=' ', header=0, names=['File', 'Label'])\n",
    "\n",
    "    train_synROD = dict(RGBfile=[], Dfile=[], Label=[])\n",
    "    test_synROD = dict(RGBfile=[], Dfile=[], Label=[])\n",
    "    train_ROD = dict(RGBfile=[], Dfile=[], Label=[])\n",
    "    test_ROD = dict(RGBfile=[], Dfile=[])\n",
    "\n",
    "    train_synROD[\"RGBfile\"] = (df_synROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"rgb\"))).map(str)\n",
    "    train_synROD[\"Dfile\"] = (df_synROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"depth\"))).map(str)\n",
    "    train_synROD[\"Label\"] = df_synROD_train[\"Label\"].values.tolist()\n",
    "\n",
    "    test_synROD[\"RGBfile\"] = (df_synROD_test[\"File\"].apply(lambda x: x.replace(\"***\", \"rgb\"))).map(str)\n",
    "    test_synROD[\"Dfile\"] = (df_synROD_test[\"File\"].apply(lambda x: x.replace(\"***\", \"depth\"))).map(str)\n",
    "    test_synROD[\"Label\"] = df_synROD_test[\"Label\"].values.tolist()\n",
    "\n",
    "    train_ROD[\"RGBfile\"] = (df_ROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"crop\"))).map(str)\n",
    "    train_ROD[\"Dfile\"] = (df_ROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"depthcrop\"))).map(str)\n",
    "\n",
    "    test_ROD[\"RGBfile\"] = (df_ROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"crop\"))).map(str)\n",
    "    test_ROD[\"Dfile\"] = (df_ROD_train[\"File\"].apply(lambda x: x.replace(\"***\", \"depthcrop\"))).map(str)\n",
    "    test_ROD[\"Label\"] = df_ROD_train[\"Label\"].values.tolist()\n",
    "\n",
    "    if type == 'Jigsaw':\n",
    "        training_data_synROD = CustomImageDataset(train_synROD[\"RGBfile\"], train_synROD[\"Dfile\"],\n",
    "                                                  img_dir=\"newdata/ROD-synROD/synROD/\",\n",
    "                                                  labels=train_synROD[\"Label\"],\n",
    "                                                  transform=True, ROD=False, Jigsaw=True)\n",
    "\n",
    "        RGB_train, RGB_test, label_train, label_test = train_test_split(test_ROD[\"RGBfile\"], test_ROD[\"Label\"],\n",
    "                                                                        test_size=0.3, random_state=42)\n",
    "        D_train, D_test, _, _ = train_test_split(test_ROD[\"Dfile\"], test_ROD[\"Label\"], test_size=0.3, random_state=42)\n",
    "        test_data = CustomImageDataset(RGB_test, D_test, img_dir=\"newdata/ROD-synROD/ROD/\",\n",
    "                                       labels=label_test, transform=True, ROD=True, Jigsaw=True)\n",
    "        training_data_ROD = CustomImageDataset(RGB_train, D_train, img_dir=\"newdata/ROD-synROD/ROD/\",\n",
    "                                               transform=True, ROD=True, Jigsaw=True)\n",
    "        train_dataloader_synROD = DataLoader(training_data_synROD, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                             num_workers=2, drop_last=True)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2, drop_last=True)\n",
    "        dataloaders = dict(train=train_dataloader_synROD, val=test_dataloader)\n",
    "    elif type == 'DA':\n",
    "\n",
    "        training_data_synROD = CustomImageDataset(train_synROD[\"RGBfile\"], train_synROD[\"Dfile\"], DoRot=True,\n",
    "                                                  img_dir=\"newdata/ROD-synROD/synROD/\",\n",
    "                                                  labels=train_synROD[\"Label\"],\n",
    "                                                  transform=True, ROD=False)\n",
    "\n",
    "        RGB_train, RGB_test, label_train, label_test = train_test_split(test_ROD[\"RGBfile\"], test_ROD[\"Label\"],\n",
    "                                                                        test_size=0.3, random_state=42)\n",
    "        D_train, D_test, _, _ = train_test_split(test_ROD[\"Dfile\"], test_ROD[\"Label\"],\n",
    "                                                 test_size=0.3, random_state=42)\n",
    "        test_data = CustomImageDataset(RGB_test, D_test, DoRot=False,\n",
    "                                       img_dir=\"newdata/ROD-synROD/ROD/\", labels=label_test,\n",
    "                                       transform=True, ROD=True)\n",
    "        training_data_ROD = CustomImageDataset(RGB_train, D_train, DoRot=True,\n",
    "                                               img_dir=\"newdata/ROD-synROD/ROD/\", transform=True, ROD=True)\n",
    "        train_dataloader_synROD = DataLoader(training_data_synROD, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                             num_workers=2, drop_last=True)\n",
    "        test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2,\n",
    "                                     drop_last=True)\n",
    "        dataloaders = dict(train=train_dataloader_synROD, val=test_dataloader)\n",
    "    else:\n",
    "        training_data_e2e = CustomImageDataset(train_synROD[\"RGBfile\"], train_synROD[\"Dfile\"], DoRot=False,\n",
    "                                               img_dir=\"newdata/ROD-synROD/synROD/\", labels=train_synROD[\"Label\"],\n",
    "                                               transform=True, ROD=False)\n",
    "        test_data_e2e = CustomImageDataset(test_ROD[\"RGBfile\"], train_ROD[\"Dfile\"], DoRot=False,\n",
    "                                           img_dir=\"newdata/ROD-synROD/ROD/\", labels=test_ROD[\"Label\"],\n",
    "                                           transform=True, ROD=True)\n",
    "        training_data_ROD = CustomImageDataset(train_ROD[\"RGBfile\"], train_ROD[\"Dfile\"], DoRot=True,\n",
    "                                               img_dir=\"newdata/ROD-synROD/ROD/\", transform=True, ROD=True)\n",
    "        train_dataloader_e2e = DataLoader(training_data_e2e, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                          num_workers=4)\n",
    "        test_dataloader_e2e = DataLoader(test_data_e2e, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                         num_workers=4)\n",
    "        dataloaders = dict(train=train_dataloader_e2e, val=test_dataloader_e2e)\n",
    "\n",
    "    train_dataloader_ROD = DataLoader(training_data_ROD, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                                      num_workers=0, drop_last=True)\n",
    "\n",
    "    return dataloaders, train_dataloader_ROD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d1caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_DA(num_epochs=20, batch_size=64, mode=\"Rotation\"):\n",
    "    FE_rgb = ResBase()\n",
    "    FE_depth = ResBase()\n",
    "    FC_M = MainHead(input_dim=512 * 2, class_num=47, dropout_p=0.5, extract=False)\n",
    "    if mode == \"Rotation\":\n",
    "        FC_P = RotationHead(input_dim=1024, class_num=4)\n",
    "        dataloaders, target_dataloader = prep_data('DA', batch_size)\n",
    "    else:\n",
    "        FC_P = RotationHead(input_dim=1024, class_num=24)\n",
    "        dataloaders, target_dataloader = prep_data('Jigsaw', batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    FE_rgb, FE_depth, FC_M, FC_P = FE_rgb.to(device), FE_depth.to(device), FC_M.to(device), FC_P.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    pretext_weight = 0.1\n",
    "    optimizers = [optim.SGD(FE_rgb.parameters(), lr=3e-3, weight_decay=0.05, momentum=0.9),\n",
    "                  optim.SGD(FE_depth.parameters(), lr=3e-3, weight_decay=0.05, momentum=0.9),\n",
    "                  optim.SGD(FC_M.parameters(), lr=3e-3, weight_decay=0.05, momentum=0.9),\n",
    "                  optim.SGD(FC_P.parameters(), lr=3e-3, weight_decay=0.05, momentum=0.9)]\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(FE_rgb.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Store losses and accuracies across epochs\n",
    "    losses, accuracies, lr = dict(train=[], val=[]), dict(train=[], val=[]), 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                FE_rgb.train()\n",
    "                FE_depth.train()\n",
    "                FC_M.train()\n",
    "                FC_P.train()\n",
    "            else:\n",
    "                FE_rgb.eval()\n",
    "                FE_depth.eval()\n",
    "                FC_M.eval()\n",
    "                FC_P.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            nsamples = 0\n",
    "            for x_source, y_source, z_source in dataloaders[phase]:  # Loading mini-batch from S\n",
    "                # Load mini-batch from S\n",
    "                x_source, y_source = x_source.to(device), y_source.to(device)\n",
    "                nsamples += x_source.shape[0]\n",
    "                for optimizer in optimizers:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Compute main loss Lm\n",
    "                    feats_rgb, _ = FE_rgb(x_source[:, [0, 1, 2]])\n",
    "                    feats_depth, _ = FE_depth(x_source[:, [3, 4, 5]])\n",
    "                    feats = torch.cat((feats_rgb, feats_depth), dim=1)\n",
    "                    pred_logits_cat = FC_M(feats)\n",
    "                    _, preds_cat = torch.max(pred_logits_cat, 1)\n",
    "                    Lm = criterion(pred_logits_cat, y_source)\n",
    "\n",
    "                    # Load mini-batches from S~ and T~\n",
    "                    x_target, _, z_target = next(iter(target_dataloader))\n",
    "\n",
    "                    # print_image(x_target[0])\n",
    "                    # print_image(x_target_tilde[0])\n",
    "                    x_target = x_target.to(device)\n",
    "\n",
    "                    InTilde = torch.zeros(size=(batch_size, 6, 224, 224), device=device)\n",
    "                    InZ = torch.zeros(size=[batch_size], device=device, dtype=torch.uint8)\n",
    "                    for idx in range(0, batch_size, 2):\n",
    "                        if mode == \"Jigsaw\":\n",
    "                            InTilde[idx] = make_jigsaw(x_source[idx], z_source[idx].item())\n",
    "                            InTilde[idx + 1] = make_jigsaw(x_target[idx], z_target[idx].item())\n",
    "                        else:\n",
    "                            rot_c = random.choice((0, 1, 2, 3))\n",
    "                            rot_d = z_source[idx].item() + rot_c\n",
    "                            if rot_d >= 4:\n",
    "                                rot_d -= 4\n",
    "                            InTilde[idx][0:3] = transforms.functional.rotate(x_source[idx][0:3], rot_c * 90)\n",
    "                            InTilde[idx][3:6] = transforms.functional.rotate(x_source[idx][3:6], rot_d * 90)\n",
    "                            rot_c = random.choice((0, 1, 2, 3))\n",
    "                            rot_d = z_target[idx].item() + rot_c\n",
    "                            if rot_d > 4:\n",
    "                                rot_d -= 4\n",
    "                            InTilde[idx + 1] = transforms.functional.rotate(x_target[idx], z_target[idx].item() * 90)\n",
    "                        InZ[idx] = z_source[idx].data\n",
    "                        InZ[idx + 1] = z_target[idx].data\n",
    "                    _, feats_rgb = FE_rgb(InTilde[:, [0, 1, 2]])\n",
    "                    _, feats_depth = FE_depth(InTilde[:, [3, 4, 5]])\n",
    "                    feats = torch.cat((feats_rgb, feats_depth), dim=1)\n",
    "                    pred_logits_rot = FC_P(feats)\n",
    "                    _, preds_rot = torch.max(pred_logits_rot, 1)\n",
    "                    Lp = criterion(pred_logits_rot, InZ)\n",
    "\n",
    "                    # Cross-entropy minimization\n",
    "                    L = Lm + (pretext_weight * Lp)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        L.backward()\n",
    "                        for optimizer in optimizers:\n",
    "                            optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += Lm.item() * (x_target.size(0))\n",
    "                running_corrects += (preds_cat == y_source.data).sum().item()\n",
    "                #print('Phase: {} Progress: {}/{} Lm: {:.4f} Lp: {:.4f} L: {:.4f}'.format(phase, nsamples, dataloaders[\n",
    "                #    phase].sampler.num_samples, Lm.item(), Lp.item(), L.item()))\n",
    "\n",
    "            epoch_loss = running_loss / nsamples\n",
    "            epoch_acc = running_corrects / nsamples\n",
    "\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            lr = optimizers[0].param_groups[0]['lr']\n",
    "            print('Phase: {} LR: {:.4f} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, lr, epoch_loss, epoch_acc))\n",
    "            with open('result_rotation.txt', 'a') as fp:\n",
    "                fp.write('Phase: {}, LR: {:.4f}, Loss: {:.4f}, Acc: {:.4f}\\n'.format(phase, lr, epoch_loss, epoch_acc))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_FC_M_wts = copy.deepcopy(FC_M.state_dict())\n",
    "                best_FC_P_wts = copy.deepcopy(FC_P.state_dict())\n",
    "                best_FE_rgb_wts = copy.deepcopy(FE_rgb.state_dict())\n",
    "                best_FE_depth_wts = copy.deepcopy(FE_depth.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    with open('result_rotation.txt', 'a') as fp:\n",
    "        fp.write(('Training complete in {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60)))\n",
    "        fp.write('Best val Acc: {:4f}\\n'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    FC_M.load_state_dict(best_FC_M_wts)\n",
    "    FC_P.load_state_dict(best_FC_P_wts)\n",
    "    FE_rgb.load_state_dict(best_FE_rgb_wts)\n",
    "    FE_depth.load_state_dict(best_FE_depth_wts)\n",
    "    return FC_M, FC_P, FE_rgb, FE_depth, losses, accuracies, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b227e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.0215 Acc: 0.7817\n",
      "Phase: val LR: 0.0030 Loss: 3.9282 Acc: 0.0134\n",
      "Epoch 2/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 0.8665 Acc: 0.9010\n",
      "Phase: val LR: 0.0030 Loss: 3.9031 Acc: 0.0077\n",
      "Epoch 3/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.2656 Acc: 0.8514\n",
      "Phase: val LR: 0.0030 Loss: 3.9110 Acc: 0.0162\n",
      "Epoch 4/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.4594 Acc: 0.8225\n",
      "Phase: val LR: 0.0030 Loss: 3.8582 Acc: 0.0156\n",
      "Epoch 5/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5027 Acc: 0.8132\n",
      "Phase: val LR: 0.0030 Loss: 3.8987 Acc: 0.0387\n",
      "Epoch 6/20\n",
      "----------\n",
      "Phase: train LR: 0.0030 Loss: 1.5104 Acc: 0.8102\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, losses, accuracies, lr = train_model_DA(num_epochs=20, batch_size=64, mode=\"Jigsaw\")\n",
    "save_filename = 'DA_rotation_true.pth'\n",
    "save_path = os.path.join('./savedModels', save_filename)\n",
    "torch.save({'FC_M_state_dict': FC_M.state_dict(),\n",
    "            'FC_P_state_dict': FC_P.state_dict(),\n",
    "            'FE_rgb_state_dict': FE_rgb.state_dict(),\n",
    "            'FE_depth_state_dict': FE_depth.state_dict(),\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_M, FC_P, FE_rgb, FE_depth, losses, accuracies, lr = train_model_DA(num_epochs=32, batch_size=64, mode=\"Rotation\")\n",
    "save_filename = 'DA_rotation_true.pth'\n",
    "save_path = os.path.join('./savedModels', save_filename)\n",
    "torch.save({'FC_M_state_dict': FC_M.state_dict(),\n",
    "            'FC_P_state_dict': FC_P.state_dict(),\n",
    "            'FE_rgb_state_dict': FE_rgb.state_dict(),\n",
    "            'FE_depth_state_dict': FE_depth.state_dict(),\n",
    "}, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
